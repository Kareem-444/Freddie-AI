# Freddie AI - Your Personal AI Assistant

<div align="center">

![Freddie AI Banner](https://via.placeholder.com/1200x300/0f172a/60a5fa?text=Freddie+AI+-+Intelligent+Desktop+Assistant)

[![Python](https://img.shields.io/badge/Python-3.11+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![Django](https://img.shields.io/badge/Django-5.0+-092E20?style=for-the-badge&logo=django&logoColor=white)](https://www.djangoproject.com/)
[![Next.js](https://img.shields.io/badge/Next.js-14+-000000?style=for-the-badge&logo=next.js&logoColor=white)](https://nextjs.org/)
[![Tauri](https://img.shields.io/badge/Tauri-2.0+-FFC131?style=for-the-badge&logo=tauri&logoColor=white)](https://tauri.app/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.0+-3178C6?style=for-the-badge&logo=typescript&logoColor=white)](https://www.typescriptlang.org/)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](LICENSE)

**A powerful, offline-first AI assistant that runs entirely on your local machine**

[Features](#features) â€¢ [Installation](#installation) â€¢ [Architecture](#architecture) â€¢ [Usage](#usage) â€¢ [Development](#development)

</div>

---

## ğŸ“– Table of Contents

- [Overview](#overview)
- [Key Features](#key-features)
- [Screenshots](#screenshots)
- [Technology Stack](#technology-stack)
- [Architecture](#architecture)
- [Installation](#installation)
- [Usage Guide](#usage-guide)
- [AI Models](#ai-models)
- [Development](#development)
- [Project Structure](#project-structure)
- [API Documentation](#api-documentation)
- [Contributing](#contributing)
- [License](#license)
- [Acknowledgments](#acknowledgments)

---

## ğŸŒŸ Overview

**Freddie AI** is a next-generation desktop AI assistant that brings the power of large language models directly to your computer. Unlike cloud-based alternatives, Freddie AI runs entirely offline, ensuring complete privacy, security, and independence from internet connectivity.

Built with modern technologies and a user-first approach, Freddie AI offers:
- ğŸ”’ **Complete Privacy** - All data stays on your device
- âš¡ **No Internet Required** - Works 100% offline after model download
- ğŸ¯ **Multiple AI Models** - Choose from 12 specialized models
- ğŸ’» **Cross-Platform** - Windows, macOS, and Linux support
- ğŸ¨ **Beautiful UI** - Modern, intuitive interface built with Next.js
- ğŸš€ **High Performance** - Optimized for CPU and GPU inference

---

## âœ¨ Key Features

### ğŸ¤– Advanced AI Capabilities
- **12 AI Models**: From lightweight (669MB) to powerful (40GB) models
- **Specialized Models**: Coding, creative writing, multilingual, and general-purpose
- **Context-Aware**: Maintains conversation history for coherent dialogues
- **Custom Prompts**: System prompts for specialized tasks

### ğŸ’¾ Smart Model Management
- **Download Manager**: Real-time progress tracking with speed and ETA
- **Pause/Resume**: Control downloads like a browser
- **Model Categories**: Organized by purpose (Coding, General, Creative, Multilingual)
- **Auto-Detection**: Automatically uses downloaded models
- **Storage Optimization**: Efficient GGUF format reduces model sizes by 75%

### ğŸ¨ User Experience
- **Modern UI**: Sleek, dark-themed interface with smooth animations
- **Chat Management**: Organize conversations by project
- **File Attachments**: Support for images and documents
- **Export/Import**: Save and share conversations
- **Customizable Settings**: Tailor the experience to your needs

### ğŸ” Privacy & Security
- **Offline-First**: No data sent to external servers
- **Local Storage**: All conversations stored locally
- **No Telemetry**: Zero tracking or analytics
- **Open Source**: Transparent codebase you can audit

---

## ğŸ“¸ Screenshots

### Main Chat Interface
<div align="center">
<img src="https://via.placeholder.com/800x500/0f172a/60a5fa?text=Chat+Interface+-+Clean+and+Modern+Design" alt="Chat Interface" width="800"/>

*Beautiful, distraction-free chat interface with real-time AI responses*
</div>

### AI Models Manager
<div align="center">
<img src="https://via.placeholder.com/800x500/0f172a/60a5fa?text=Models+Manager+-+Download+and+Manage+AI+Models" alt="Models Manager" width="800"/>

*Intuitive model management with categories, search, and download controls*
</div>

### Download Progress
<div align="center">
<img src="https://via.placeholder.com/800x500/0f172a/60a5fa?text=Download+Progress+-+Real-time+Tracking" alt="Download Progress" width="800"/>

*Real-time download progress with speed, ETA, and pause/resume controls*
</div>

### Settings & Configuration
<div align="center">
<img src="https://via.placeholder.com/800x500/0f172a/60a5fa?text=Settings+-+Customize+Your+Experience" alt="Settings" width="800"/>

*Comprehensive settings for personalizing your AI assistant*
</div>

---

## ğŸ› ï¸ Technology Stack

### Frontend
| Technology | Purpose | Version |
|------------|---------|---------|
| ![Next.js](https://img.shields.io/badge/Next.js-000000?style=flat&logo=next.js&logoColor=white) | React framework | 14.x |
| ![TypeScript](https://img.shields.io/badge/TypeScript-3178C6?style=flat&logo=typescript&logoColor=white) | Type-safe JavaScript | 5.x |
| ![Tauri](https://img.shields.io/badge/Tauri-FFC131?style=flat&logo=tauri&logoColor=white) | Desktop app framework | 2.x |
| ![TailwindCSS](https://img.shields.io/badge/Tailwind-38B2AC?style=flat&logo=tailwind-css&logoColor=white) | Utility-first CSS | 3.x |
| ![React Icons](https://img.shields.io/badge/React_Icons-61DAFB?style=flat&logo=react&logoColor=white) | Icon library | Latest |

### Backend
| Technology | Purpose | Version |
|------------|---------|---------|
| ![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white) | Backend language | 3.11+ |
| ![Django](https://img.shields.io/badge/Django-092E20?style=flat&logo=django&logoColor=white) | Web framework | 5.x |
| ![llama.cpp](https://img.shields.io/badge/llama.cpp-000000?style=flat&logo=c%2B%2B&logoColor=white) | LLM inference | Latest |
| ![HuggingFace](https://img.shields.io/badge/HuggingFace-FFD21E?style=flat&logo=huggingface&logoColor=black) | Model repository | Hub API |

### AI & ML
| Library | Purpose |
|---------|---------|
| **llama-cpp-python** | Python bindings for llama.cpp |
| **GGUF Models** | Quantized model format |
| **HuggingFace Hub** | Model downloads |

---

## ğŸ—ï¸ Architecture

### System Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Freddie AI Desktop App                  â”‚
â”‚                        (Tauri + Next.js)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ HTTP/JSON API
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Django Backend Server                     â”‚
â”‚                     (Python 3.11+)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Views.py  â”‚  â”‚ Model        â”‚  â”‚  AI Models      â”‚   â”‚
â”‚  â”‚   (API      â”‚â”€â–¶â”‚ Manager      â”‚â”€â–¶â”‚  Config         â”‚   â”‚
â”‚  â”‚  Endpoints) â”‚  â”‚ (Downloads,  â”‚  â”‚  (12 Models)    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  Inference)  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                           â”‚                                 â”‚
â”‚                           â–¼                                 â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                  â”‚  llama.cpp     â”‚                         â”‚
â”‚                  â”‚  (Inference    â”‚                         â”‚
â”‚                  â”‚   Engine)      â”‚                         â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚  GGUF Models    â”‚
                  â”‚  (~/.freddie_ai)â”‚
                  â”‚  - TinyLlama    â”‚
                  â”‚  - Qwen Coder   â”‚
                  â”‚  - Llama 3.1    â”‚
                  â”‚  - And more...  â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

```
User Input â†’ Frontend (Next.js) â†’ Backend (Django) â†’ Model Manager
                                                           â†“
                                                    Load Model (llama.cpp)
                                                           â†“
                                                    Generate Response
                                                           â†“
                                           Return Response â† Backend â† Frontend
```

### Component Architecture

```
Freddie AI/
â”œâ”€â”€ Frontend (Next.js + Tauri)
â”‚   â”œâ”€â”€ UI Components
â”‚   â”‚   â”œâ”€â”€ Chat Interface
â”‚   â”‚   â”œâ”€â”€ Model Manager
â”‚   â”‚   â”œâ”€â”€ Settings Panel
â”‚   â”‚   â””â”€â”€ Download Manager
â”‚   â”œâ”€â”€ State Management
â”‚   â”‚   â”œâ”€â”€ Chat History
â”‚   â”‚   â”œâ”€â”€ Active Model
â”‚   â”‚   â””â”€â”€ Download Status
â”‚   â””â”€â”€ API Client (Axios)
â”‚
â”œâ”€â”€ Backend (Django)
â”‚   â”œâ”€â”€ REST API Endpoints
â”‚   â”‚   â”œâ”€â”€ /api/modules/          # List models
â”‚   â”‚   â”œâ”€â”€ /api/modules/download/ # Download model
â”‚   â”‚   â”œâ”€â”€ /api/modules/pause/    # Pause download
â”‚   â”‚   â”œâ”€â”€ /api/modules/resume/   # Resume download
â”‚   â”‚   â”œâ”€â”€ /api/modules/cancel/   # Cancel download
â”‚   â”‚   â””â”€â”€ /api/chat/             # Chat completion
â”‚   â”œâ”€â”€ Model Manager
â”‚   â”‚   â”œâ”€â”€ Download Handler
â”‚   â”‚   â”œâ”€â”€ Progress Tracker
â”‚   â”‚   â””â”€â”€ Model Loader
â”‚   â””â”€â”€ AI Engine
â”‚       â”œâ”€â”€ Model Configuration
â”‚       â””â”€â”€ Inference Engine
â”‚
â””â”€â”€ Storage Layer
    â”œâ”€â”€ Models Directory (~/.freddie_ai/models/)
    â”œâ”€â”€ Chat History (localStorage)
    â””â”€â”€ User Preferences (localStorage)
```

---

## ğŸ“¥ Installation

### Prerequisites

Before installing Freddie AI, ensure you have:

- **Operating System**: Windows 10+, macOS 10.15+, or Linux
- **RAM**: 8GB minimum (16GB+ recommended for larger models)
- **Disk Space**: 10GB+ for models
- **Python**: 3.11 or higher
- **Node.js**: 18.x or higher
- **Git**: For cloning the repository

### Quick Start

#### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/freddie-ai.git
cd freddie-ai
```

#### 2. Backend Setup

```bash
# Navigate to backend directory
cd backend

# Create virtual environment
python -m venv backend-env

# Activate virtual environment
# Windows:
backend-env\Scripts\activate
# macOS/Linux:
source backend-env/bin/activate

# Install dependencies
pip install -r requirements.txt

# Install AI inference library
pip install llama-cpp-python --break-system-packages

# Run Django server
python manage.py runserver 8000
```

#### 3. Frontend Setup

```bash
# Open new terminal
cd frontend

# Install dependencies
npm install

# Run development server
npm run dev
```

#### 4. Access Freddie AI

Open your browser and navigate to:
```
http://localhost:3000
```

### Production Build

#### Desktop App (Tauri)

```bash
cd frontend

# Build Tauri app
npm run tauri build

# Installer will be in: src-tauri/target/release/bundle/
```

---

## ğŸ¯ Usage Guide

### First-Time Setup

#### 1. Download Your First AI Model

When you first open Freddie AI, you'll be greeted with the Models Manager:

1. **Browse Available Models** - 12 models organized by category
2. **Choose a Model** - Start with `Qwen2.5 Coder 1.5B` (recommended for beginners)
3. **Click "Get"** - Download begins automatically
4. **Monitor Progress** - Watch real-time download progress
5. **Start Chatting** - Once downloaded, you're ready to go!

#### 2. Your First Conversation

```
You: Hello! Can you help me write a Python function?

Freddie AI: Hello! I'd be happy to help you write a Python function. 
What would you like the function to do?

You: Create a function that calculates fibonacci numbers

Freddie AI: Here's a Python function to calculate Fibonacci numbers:

def fibonacci(n):
    """Calculate the nth Fibonacci number."""
    if n <= 0:
        return 0
    elif n == 1:
        return 1
    else:
        return fibonacci(n-1) + fibonacci(n-2)

# Example usage:
print(fibonacci(10))  # Output: 55
```

### Managing Models

#### Download Models

1. Click **Settings** icon (âš™ï¸) in sidebar
2. Navigate to **AI Models** tab
3. Browse or search for models
4. Click **Get** to download
5. Monitor progress with:
   - Real-time percentage
   - Download speed (MB/s)
   - Estimated time remaining

#### Download Controls

- **â¸ï¸ Pause** - Temporarily pause download
- **â–¶ï¸ Resume** - Continue paused download
- **ğŸ›‘ Cancel** - Stop and delete partial download
- **ğŸ—‘ï¸ Delete** - Remove downloaded model

#### Switch Models

1. Click model selector in chat header
2. Choose from downloaded models
3. Model loads automatically
4. Continue chatting with new model

---

## ğŸ¤– AI Models

Freddie AI offers 12 carefully selected AI models optimized for different tasks:

### ğŸ“Š Models Overview

| Model | Size | Speed | Quality | Best For | RAM Required |
|-------|------|-------|---------|----------|--------------|
| **TinyLlama 1.1B** | 669 MB | âš¡âš¡âš¡ | â­â­ | Quick responses | 2 GB |
| **Qwen2.5 Coder 1.5B** â­ | 986 MB | âš¡âš¡âš¡ | â­â­â­ | Coding tasks | 3 GB |
| **Llama 3.2 3B** â­ | 2.0 GB | âš¡âš¡âš¡ | â­â­â­â­ | General conversation | 4 GB |
| **DeepSeek Coder 6.7B** | 4.1 GB | âš¡âš¡ | â­â­â­â­â­ | Advanced coding | 8 GB |
| **Qwen2.5 Coder 7B** â­ | 4.7 GB | âš¡âš¡ | â­â­â­â­â­ | Professional coding | 8 GB |
| **Mistral 7B** | 4.4 GB | âš¡âš¡ | â­â­â­â­ | Creative writing | 8 GB |
| **Llama 3.1 8B** â­ | 4.9 GB | âš¡âš¡ | â­â­â­â­â­ | Best all-rounder | 10 GB |
| **CodeLlama 13B** | 7.4 GB | âš¡ | â­â­â­â­â­ | Meta's code model | 16 GB |
| **Qwen2.5 14B** | 8.9 GB | âš¡ | â­â­â­â­â­ | Multilingual | 16 GB |
| **Qwen2.5 32B** | 18 GB | âš¡ | â­â­â­â­â­ | Advanced multilingual | 24 GB |
| **Mixtral 8x7B** | 26 GB | âš¡ | â­â­â­â­â­ | Creative expert (MoE) | 32 GB |
| **Llama 3.1 70B** | 40 GB | âš¡ | â­â­â­â­â­ | GPT-4 class | 48 GB |

â­ = Recommended models

### ğŸ’» Coding Models

Perfect for software development, debugging, and code explanations:

- **Qwen2.5 Coder 1.5B** - Fast, lightweight coding assistant
- **Qwen2.5 Coder 7B** - Advanced code generation and debugging
- **DeepSeek Coder 6.7B** - Specialized for complex programming
- **CodeLlama 13B** - Meta's powerful code generation model

### ğŸŒŸ General Purpose Models

Best for conversations, questions, and general tasks:

- **TinyLlama 1.1B** - Ultra-fast for quick queries
- **Llama 3.2 3B** - Balanced performance
- **Llama 3.1 8B** - Flagship model with excellent reasoning
- **Llama 3.1 70B** - GPT-4 level performance

### ğŸ¨ Creative Models

Optimized for creative writing, storytelling, and content generation:

- **Mistral 7B** - Creative writing specialist
- **Mixtral 8x7B** - Mixture of Experts for creative tasks

### ğŸŒ Multilingual Models

Excellent for multiple languages and translation:

- **Qwen2.5 14B** - Strong multilingual support
- **Qwen2.5 32B** - Top-tier multilingual AI

---

## ğŸ‘¨â€ğŸ’» Development

### Development Setup

#### Backend Development

```bash
cd backend
backend-env\Scripts\activate  # Windows
source backend-env/bin/activate  # macOS/Linux

# Run with auto-reload
python manage.py runserver 8000

# Run tests
python manage.py test

# Create migrations
python manage.py makemigrations
python manage.py migrate
```

#### Frontend Development

```bash
cd frontend

# Development server with hot reload
npm run dev

# Type checking
npm run type-check

# Linting
npm run lint

# Build for production
npm run build
```

### Adding New Features

#### Adding a New AI Model

1. **Update `ai_models.py`**:
```python
{
    "id": "new-model-id",
    "display_name": "New Model Name",
    "description": "Model description",
    "category": "coding",  # or general, creative, multilingual
    "size": "X.X GB",
    "size_bytes": XXXXXXXXX,
    "parameters": "XXB",
    "context_length": 8192,
    "n_threads": 6,
    "hf_repo": "author/model-name",
    "hf_filename": "model-file.gguf",
    "recommended": False,
    "bundled": False,
    "speed": "âš¡âš¡",
    "quality": "â­â­â­â­"
}
```

2. **Restart Django server**
3. **Model appears in UI automatically**

#### Adding New API Endpoints

1. **Create view in `views.py`**:
```python
@csrf_exempt
@require_http_methods(["POST"])
def my_new_endpoint(request):
    try:
        data = json.loads(request.body)
        # Process request
        return JsonResponse({"status": "success"})
    except Exception as e:
        return JsonResponse({"error": str(e)}, status=500)
```

2. **Add route in `urls.py`**:
```python
path('my-endpoint/', views.my_new_endpoint, name='my_endpoint'),
```

3. **Use in frontend**:
```typescript
const response = await axios.post('http://localhost:8000/api/my-endpoint/', {
    data: "value"
});
```

### Code Style Guidelines

#### Python (Backend)
- Follow PEP 8
- Use type hints
- Docstrings for all functions
- Maximum line length: 100 characters

#### TypeScript (Frontend)
- Follow Airbnb style guide
- Use functional components with hooks
- Props interface for all components
- Maximum line length: 100 characters

---

## ğŸ“ Project Structure

```
freddie-ai/
â”œâ”€â”€ backend/                      # Django backend
â”‚   â”œâ”€â”€ ai_engine/               # AI engine app
â”‚   â”‚   â”œâ”€â”€ models.py           # Django models
â”‚   â”‚   â”œâ”€â”€ views.py            # API endpoints
â”‚   â”‚   â”œâ”€â”€ urls.py             # URL routing
â”‚   â”‚   â”œâ”€â”€ ai_models.py        # AI model configurations
â”‚   â”‚   â””â”€â”€ model_manager.py    # Model download & inference
â”‚   â”œâ”€â”€ backend/                 # Django project settings
â”‚   â”‚   â”œâ”€â”€ settings.py
â”‚   â”‚   â”œâ”€â”€ urls.py
â”‚   â”‚   â””â”€â”€ wsgi.py
â”‚   â”œâ”€â”€ manage.py
â”‚   â””â”€â”€ requirements.txt         # Python dependencies
â”‚
â”œâ”€â”€ frontend/                     # Next.js + Tauri frontend
â”‚   â”œâ”€â”€ app/                     # Next.js app directory
â”‚   â”‚   â”œâ”€â”€ components/          # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ Chat.tsx        # Main chat interface
â”‚   â”‚   â”‚   â”œâ”€â”€ Sidebar.tsx     # Navigation sidebar
â”‚   â”‚   â”‚   â”œâ”€â”€ SettingsPage.tsx # Settings & models
â”‚   â”‚   â”‚   â”œâ”€â”€ InputBar.tsx    # Message input
â”‚   â”‚   â”‚   â”œâ”€â”€ MessageBubble.tsx # Chat messages
â”‚   â”‚   â”‚   â”œâ”€â”€ ProjectsPage.tsx # Project management
â”‚   â”‚   â”‚   â””â”€â”€ ImagesPage.tsx  # Image gallery
â”‚   â”‚   â”œâ”€â”€ page.tsx            # Main app page
â”‚   â”‚   â”œâ”€â”€ layout.tsx          # App layout
â”‚   â”‚   â””â”€â”€ globals.css         # Global styles
â”‚   â”œâ”€â”€ public/                  # Static assets
â”‚   â”œâ”€â”€ src-tauri/              # Tauri desktop app
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ icons/
â”‚   â”‚   â”œâ”€â”€ Cargo.toml
â”‚   â”‚   â””â”€â”€ tauri.conf.json
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”œâ”€â”€ tailwind.config.ts
â”‚   â””â”€â”€ next.config.js
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md                    # This file
```

---

## ğŸ“¡ API Documentation

### Base URL
```
http://localhost:8000/api/
```

### Endpoints

#### 1. List All Models
```http
GET /modules/
```

**Response:**
```json
{
  "modules": [
    {
      "id": "qwen2.5-coder-1.5b",
      "display_name": "Qwen2.5 Coder 1.5B",
      "description": "Fast coding assistant",
      "category": "coding",
      "size": "986 MB",
      "downloaded": true,
      "download_status": {
        "status": "completed",
        "progress": 100
      }
    }
  ]
}
```

#### 2. Download Model
```http
POST /modules/download/
Content-Type: application/json

{
  "module_id": "tinyllama-1.1b"
}
```

**Response:**
```json
{
  "status": "downloading",
  "message": "Downloading TinyLlama 1.1B..."
}
```

#### 3. Check Download Status
```http
GET /modules/download-status/{module_id}/
```

**Response:**
```json
{
  "status": "downloading",
  "progress": 47,
  "downloaded_bytes": 314000000,
  "total_bytes": 669000000,
  "speed": 2100000,
  "eta": 120
}
```

#### 4. Pause Download
```http
POST /modules/pause/
Content-Type: application/json

{
  "module_id": "tinyllama-1.1b"
}
```

#### 5. Resume Download
```http
POST /modules/resume/
Content-Type: application/json

{
  "module_id": "tinyllama-1.1b"
}
```

#### 6. Cancel Download
```http
POST /modules/cancel/
Content-Type: application/json

{
  "module_id": "tinyllama-1.1b"
}
```

#### 7. Delete Model
```http
POST /modules/delete/
Content-Type: application/json

{
  "module_id": "tinyllama-1.1b"
}
```

#### 8. Chat Completion
```http
POST /chat/
Content-Type: application/json

{
  "module_id": "qwen2.5-coder-1.5b",
  "message": "Write a Python function to sort a list",
  "history": [
    {
      "role": "user",
      "content": "Hello"
    },
    {
      "role": "assistant",
      "content": "Hi! How can I help?"
    }
  ]
}
```

**Response:**
```json
{
  "response": "Here's a Python function to sort a list:\n\ndef sort_list(arr):\n    return sorted(arr)",
  "module_name": "Qwen2.5 Coder 1.5B"
}
```

---

## ğŸ¤ Contributing

We welcome contributions from the community! Here's how you can help:

### Ways to Contribute

1. **ğŸ› Report Bugs** - Open an issue with reproduction steps
2. **ğŸ’¡ Suggest Features** - Share your ideas for improvements
3. **ğŸ“ Improve Documentation** - Help make docs clearer
4. **ğŸ”§ Submit Pull Requests** - Fix bugs or add features
5. **ğŸŒ Translations** - Help translate the UI

### Development Workflow

1. **Fork the repository**
2. **Create a feature branch** (`git checkout -b feature/amazing-feature`)
3. **Make your changes**
4. **Test thoroughly**
5. **Commit your changes** (`git commit -m 'Add amazing feature'`)
6. **Push to branch** (`git push origin feature/amazing-feature`)
7. **Open a Pull Request**

### Code Review Process

1. All PRs require at least one review
2. All tests must pass
3. Code must follow style guidelines
4. Documentation must be updated

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

```
MIT License

Copyright (c) 2026 Freddie AI Team

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
```

---

## ğŸ™ Acknowledgments

### Built With Amazing Open Source Projects

- **[llama.cpp](https://github.com/ggerganov/llama.cpp)** - Efficient LLM inference
- **[Django](https://www.djangoproject.com/)** - Python web framework
- **[Next.js](https://nextjs.org/)** - React framework
- **[Tauri](https://tauri.app/)** - Desktop app framework
- **[TailwindCSS](https://tailwindcss.com/)** - Utility-first CSS
- **[HuggingFace](https://huggingface.co/)** - Model repository

### AI Models

Special thanks to the teams behind these incredible models:

- **Meta AI** - Llama 3.1, CodeLlama
- **Alibaba** - Qwen2.5 series
- **Mistral AI** - Mistral, Mixtral
- **DeepSeek** - DeepSeek Coder

### Community

Thank you to all contributors who have helped make Freddie AI better!

---

## ğŸ“ Support & Contact

### Need Help?

- ğŸ“– **Documentation**: [docs.freddie-ai.com](https://docs.freddie-ai.com)
- ğŸ’¬ **Discord**: [Join our community](https://discord.gg/freddie-ai)
- ğŸ› **Issues**: [GitHub Issues](https://github.com/yourusername/freddie-ai/issues)
- ğŸ“§ **Email**: support@freddie-ai.com

### Stay Updated

- ğŸŒŸ **Star this repo** to stay updated
- ğŸ‘ï¸ **Watch releases** for new features
- ğŸ¦ **Follow us on Twitter**: [@FreddieAI](https://twitter.com/FreddieAI)

---

## ğŸ—ºï¸ Roadmap

### Current Version: 1.0.0

### Upcoming Features

#### v1.1.0 (Q2 2026)
- [ ] GPU acceleration support (CUDA, Metal)
- [ ] Voice input/output
- [ ] Plugin system
- [ ] Cloud sync (optional)

#### v1.2.0 (Q3 2026)
- [ ] Multi-user support
- [ ] Advanced RAG (Retrieval Augmented Generation)
- [ ] Web browser integration
- [ ] Mobile app (iOS/Android)

#### v2.0.0 (Q4 2026)
- [ ] Custom model training
- [ ] Team collaboration features
- [ ] Advanced analytics
- [ ] Enterprise features

---

<div align="center">

### Made by kareem alsayid

**Built for Privacy â€¢ Designed for Power â€¢ Created for You**

[â¬† Back to Top](#-freddie-ai---your-personal-ai-assistant)

</div>
